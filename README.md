## Дипломная работа
*фев'24*

<hr>

### Структура каталога

```
MLBasic202308
├── assets                  - иллюстрации, экспортированные графики, материалы в pdf
├── data                    - данные для анализа
├── logs                    - логи итерационных процессов
├── logreg.ipynb            - ОСНОВНОЙ ФАЙЛ
├── test_RegLogReg.py       - простое тестирование класса unittest
├── feature_generator.py    - генератор случайных сбалансированных датасетов для Логистической регрессии
├── utils.py                - вспомогательные функции и методы
└── _work                   - Рабочая папка с материалами /оставлена для своих задач автора/

```

### Основные ссылки
<hr>

Файл с [jupyter notebook](logreg.ipynb)

Реализация класса [RegLogReg](rlr.py)
<br><br>

### Реализация логистической регрессии с регуляризацией и использованием градиентного спуска
<hr>

**Цель:** 
отработать технику разработки модулей(PyCharm) для их использования в jupyter notebook

**Проведенные работы**
- подготовлен класс RegLogReg с интерфесом fit, predict, probe
  - разработка класса проведена с использованием ABC
  - класс снабжен дополнительным методом для визуализации (экспорт в png)
  - основные параметры могут быть настроены, для удобства использования проставлены дефолтные значения
- дополнительные работы:
  - написан простой тест [test_RegLogReg.py](test_RegLogReg.py) unittest
  - итерационный процесс логирован в папку logs, пример - [rlr.py_20240303-140739_.log](logs%2Frlr.py_20240303-140739_.log)
  - создана и сохранена иллюстрация ![RegLogReg_01_X_train.png](assets%2FRegLogReg_01_X_train.png)
  - написаны вспомогательные утилиты и генератор случайных сбалансированных датасетов для Логистической регрессии на базе ```make_classification``` с сохранением в файл
- созданный класс применен в jupyter notebook, где проведены следующие работы:
  - простой EDA датасета с числовыми фичами
  - базовая доработка данных 
  - реализовано моделирование на основе разработанного класса
  - результат сравнен с базовым алгоритмом
**Использованные материалы (указаны частично)**
- [CS231n](http://vision.stanford.edu/teaching/cs231n/): Deep Learning for Computer Vision - структурный подход к коду, gradient_check.py
- [Открытый курс машинного обучения](https://habr.com/ru/companies/ods/articles/323890/) (habr)
  - [Логистическая регрессия](https://github.com/Yorko/mlcourse.ai/blob/main/jupyter_russian/topic04_linear_models/topic4_linear_models_part2_logit_likelihood_learning.ipynb) (github) и метод максимального правдоподобия
- [habr](https://habr.com/ru/companies/io/articles/265007/) Легко понять логистическую регрессию (2015 год)
- Предварительная подготовка данных в Python. [Том 2](assets%2F247fk5zkamjcirbycqmq8mhp7c5krrc6.pdf). План, примеры и метрики качества
- Сбалансированные данные – успех в ML: Oversampling и Undersampling [habr](https://habr.com/ru/companies/otus/articles/781042/)
- [Векторизация](https://habr.com/ru/companies/lanit/articles/594759/) данных и кластерный анализ для улучшения рекомендательной системы
- Ряд работ Груздева А и других авторов, к которым удалось получить доступ в бумажном и электронном виде.

